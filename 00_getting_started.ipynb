{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will help install all the required dependencies as well as prepare the dataset for use with fast.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check python version\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -y libsndfile1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install fastai\n",
    "!pip3 install fastai kaggle soundfile torchaudio librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the Kaggle’s public API, you must first authenticate using an API token. From the site header, click on your user profile picture, then on “My Account” from the dropdown menu. This will take you to your account settings at https://www.kaggle.com/account. Scroll down to the section of the page labelled API:\n",
    "\n",
    "To create a new token, click on the “Create New API Token” button. This will download a fresh authentication token onto your machine.\n",
    "\n",
    "### Accept the rules\n",
    "\n",
    "https://www.kaggle.com/competitions/whale-detection-challenge/rules\n",
    "\n",
    "\n",
    "### Upload your `kaggle.json` to the same folder as this notebook then run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle; mv kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c whale-detection-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset for Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf full_data; rm -rf sample_data; rm -rf tmp_data; #remove any existing extracted data\n",
    "!unzip -q whale-detection-challenge.zip -d data/ #unzip main file\n",
    "!unzip -q data/small_data_sample_revised.zip -d sample_data/ #unzip sample data\n",
    "!unzip -q data/whale_data.zip -d tmp_data/ #unzip full data\n",
    "!rm -rf data/; rm -rf tmp_data/data/test; #remove unneeded files. official test data isn't used because we don't have labels\n",
    "!mkdir full_data; mv tmp_data/data/train full_data/audio; #move stuff around\n",
    "!mv tmp_data/data/train.csv full_data/labels.csv #rename labels\n",
    "!rm -rf tmp_data #remove tmp directory\n",
    "!mkdir -p full_data/whale; mkdir -p full_data/not_whale; #create necessary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_ROOT_DIR=os.path.normpath(os.path.join(os.getcwd(), 'full_data'))\n",
    "DATA_META_FILE=os.path.join(DATA_ROOT_DIR, 'labels.csv')\n",
    "DATA_AUDIO_DIR=os.path.join(DATA_ROOT_DIR, 'audio')\n",
    "DATA_WHALE_AUDIO_DIR=os.path.join(DATA_ROOT_DIR, 'whale')\n",
    "DATA_NOT_WHALE_AUDIO_DIR=os.path.join(DATA_ROOT_DIR, 'not_whale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(DATA_META_FILE)\n",
    "df.head()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    clip_name = row['clip_name']\n",
    "    label = row['label']\n",
    "    source_path = os.path.join(DATA_AUDIO_DIR, clip_name)\n",
    "    not_whale_destination_path = os.path.join(DATA_NOT_WHALE_AUDIO_DIR, clip_name)\n",
    "    whale_destination_path = os.path.join(DATA_WHALE_AUDIO_DIR, clip_name)\n",
    "    try:\n",
    "        if(label==0): #not whale\n",
    "            shutil.move(source_path, not_whale_destination_path)\n",
    "        else: #whale\n",
    "            shutil.move(source_path, whale_destination_path)\n",
    "    except:\n",
    "        print(f\"Could not move file. Possibly already moved. {source_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf full_data/audio; rm -rf full_data/labels.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
