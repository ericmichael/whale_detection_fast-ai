{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains all the main external libs we'll use\n",
    "from fastai.imports import * #used for fastai\n",
    "from IPython import display #used to display media in notebook\n",
    "import soundfile as sf #used to load sound files\n",
    "import matplotlib.pyplot as plt #used to plot in notebook\n",
    "import scipy\n",
    "from scipy.signal import hann\n",
    "from scipy.fftpack import rfft\n",
    "\n",
    "import pandas as pd\n",
    "from fastai.data.all import *\n",
    "from fastai.vision.all import *\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the metadata file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio loading based on: https://github.com/limazix/audio-processing/blob/master/audio_classifier_fastai.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spec, title=None, ylabel=\"freq_bin\", aspect=\"auto\", xmax=None):\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    axs.set_title(title or \"Spectrogram (db)\")\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xlabel(\"frame\")\n",
    "    im = axs.imshow(librosa.power_to_db(spec), origin=\"lower\", aspect=aspect)\n",
    "    if xmax:\n",
    "        axs.set_xlim((0, xmax))\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "def to_specgram(audio_file, n_fft=256):\n",
    "    waveform, sample_rate = torchaudio.load(audio_file)\n",
    "    transform = torchaudio.transforms.Spectrogram(n_fft=n_fft)\n",
    "    spectrogram = transform(waveform)\n",
    "    return spectrogram[0]\n",
    "\n",
    "class SpecgramTransform(Transform):\n",
    "    def __init__(self): self.aug = to_specgram\n",
    "    def encodes(self, audio_file: Path):\n",
    "        aug_img = self.aug(audio_file)\n",
    "        return aug_img\n",
    "\n",
    "files = get_files(path)\n",
    "file = files[0]\n",
    "s = to_specgram(file)\n",
    "plot_spectrogram(s, title='Example to see if data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(DATA_ROOT_DIR)\n",
    "tfm = SpecgramTransform()\n",
    "dblock = DataBlock(\n",
    "    blocks    = (TransformBlock, CategoryBlock),\n",
    "    get_items = get_files,\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms = [ tfm ]\n",
    ")\n",
    "dls = dblock.dataloaders(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
